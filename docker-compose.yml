services:
  litellm:
    # TODO: Pin to SHA digest instead of mutable tag for supply chain security
    # Example: ghcr.io/berriai/litellm@sha256:abc123...
    # Get digest: docker pull ghcr.io/berriai/litellm:main-latest && docker inspect --format='{{index .RepoDigests 0}}' ghcr.io/berriai/litellm:main-latest
    image: ghcr.io/berriai/litellm:main-latest
    expose:
      - "4000"
    volumes:
      - ./services/litellm/config.yaml:/app/config.yaml
    command: [ "--config", "/app/config.yaml", "--port", "4000" ]
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  agent:
    build:
      context: ./services/agent
      dockerfile: Dockerfile
      # Optional: Enable Node.js and Gemini CLI (adds ~350MB to image)
      # Uncomment the following lines to enable:
      # args:
      #   INCLUDE_NODEJS: "true"
    image: ai-agent-platform-agent:latest
    env_file:
      - .env
    volumes:
      - ./services/agent/config:/app/config:ro
      - ./services/agent/alembic:/app/alembic
      - ./services/agent/alembic.ini:/app/alembic.ini
      - ./skills:/app/skills:ro
      - ./services/agent/src:/app/src
      - ./services/agent/tests:/app/tests
      - ./services/agent/scripts:/app/scripts
      - ./services/agent/pyproject.toml:/app/pyproject.toml
      - ./services/agent/data:/app/data  # Bind mount for trace logs (accessible from host)
    environment:
      AGENT_ENVIRONMENT: ${AGENT_ENVIRONMENT:-production}
      QDRANT_URL: http://qdrant:6333
      SEARXNG_URL: http://searxng:8080
      POSTGRES_URL: ${POSTGRES_URL:-postgresql+asyncpg://postgres:postgres@postgres:5432/agent_db}
      LITELLM_BASE_URL: http://litellm:4000
      SKILLS_DIR: /app/skills
      # Azure DevOps Integration
      AZURE_DEVOPS_ORG: ${AZURE_DEVOPS_ORG:-}
      AZURE_DEVOPS_PROJECT: ${AZURE_DEVOPS_PROJECT:-}
      AZURE_DEVOPS_PAT: ${AZURE_DEVOPS_PAT:-}
      # Entra ID OAuth for Admin Portal
      AGENT_ENTRA_CLIENT_ID: ${MICROSOFT_CLIENT_ID:-}
      AGENT_ENTRA_CLIENT_SECRET: ${MICROSOFT_CLIENT_SECRET:-}
      AGENT_ENTRA_TENANT_ID: ${MICROSOFT_CLIENT_TENANT_ID:-}
      AGENT_ADMIN_JWT_SECRET: ${AGENT_ADMIN_JWT_SECRET:-}
    # Port NOT exposed externally - only accessible via internal Docker network
    # This is a SECURITY REQUIREMENT: agent trusts X-OpenWebUI-* headers
    # ports:
    #   - "8000:8000"
    expose:
      - "8000"
    depends_on:
      qdrant:
        condition: service_started
      searxng:
        condition: service_started
      postgres:
        condition: service_started
      litellm:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    labels:
      # Traefik disabled by default - enabled in environment-specific overrides
      # This prevents router conflicts when running multiple environments
      - "traefik.enable=false"

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD environment variable required}
      POSTGRES_DB: ${POSTGRES_DB:-agent_db}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # Internal only - uncomment for local debugging
    # ports:
    #   - "5432:5432"
    expose:
      - "5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  qdrant:
    # TODO: Pin to SHA digest instead of mutable tag for supply chain security
    # Example: qdrant/qdrant@sha256:def456...
    # Get digest: docker pull qdrant/qdrant:latest && docker inspect --format='{{index .RepoDigests 0}}' qdrant/qdrant:latest
    image: qdrant/qdrant:latest
    # Internal only - uncomment for local debugging
    # ports:
    #   - "6333:6333"
    expose:
      - "6333"
    volumes:
      - ./data/qdrant:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  searxng:
    image: ${SEARXNG_IMAGE:-searxng/searxng:latest}
    # Internal only - uncomment for local debugging
    # ports:
    #   - "${SEARXNG_PORT:-8080}:8080"
    expose:
      - "8080"
    volumes:
      - ./services/searxng/settings.yml:/etc/searxng/settings.yml
    environment:
      SEARXNG_BASE_URL: http://searxng:8080/
      SEARXNG_SECRET: ${SEARXNG_SECRET:?SEARXNG_SECRET environment variable required}
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/"]
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  open-webui:
    image: ghcr.io/open-webui/open-webui:0.8.3
    # Port exposed via Traefik, not directly
    # ports:
    #   - "3000:8080"
    environment:
      # OpenAI-compatible backend (our agent)
      - OPENAI_API_BASE_URL=http://agent:8000/v1
      - OPENAI_API_KEY=${AGENT_INTERNAL_API_KEY:-sk-dummy}
      # Disable Ollama (we only use OpenAI-compatible backend)
      - ENABLE_OLLAMA_API=false
      # Disable arena model evaluation
      - ENABLE_EVALUATION_ARENA_MODELS=false
      # Ensure env vars override DB-persisted config on restart
      - RESET_CONFIG_ON_START=true
      # Microsoft Entra ID Authentication
      - MICROSOFT_CLIENT_ID=${MICROSOFT_CLIENT_ID:-}
      - MICROSOFT_CLIENT_SECRET=${MICROSOFT_CLIENT_SECRET:-}
      - MICROSOFT_CLIENT_TENANT_ID=${MICROSOFT_CLIENT_TENANT_ID:-}
      - OPENID_PROVIDER_URL=https://login.microsoftonline.com/${MICROSOFT_CLIENT_TENANT_ID:-common}/v2.0/.well-known/openid-configuration
      # OAuth role management (sync admin status from Entra ID)
      - ENABLE_OAUTH_ROLE_MANAGEMENT=true
      - OAUTH_ROLES_CLAIM=roles
      - OAUTH_ADMIN_ROLES=${OAUTH_ADMIN_ROLES:-platform-admin}
      # Forward user identity to backend
      - ENABLE_FORWARD_USER_INFO_HEADERS=true
      # Allow new users to sign up via OAuth
      - ENABLE_OAUTH_SIGNUP=true
      # Session settings
      - WEBUI_SECRET_KEY=${OPENWEBUI_SECRET}
      # Public URL for OAuth callbacks
      - WEBUI_URL=https://${DOMAIN:-agent.falle.se}
      # Disable telemetry
      - SCARF_NO_ANALYTICS=true
      - DO_NOT_TRACK=true
      - ANONYMIZED_TELEMETRY=false
    volumes:
      - ./data/openwebui:/app/backend/data
    depends_on:
      - agent
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    labels:
      # Traefik disabled by default - enabled in environment-specific overrides
      # This prevents router conflicts when running multiple environments
      - "traefik.enable=false"

  vault-mcp:
    build: ./services/vault-mcp
    expose:
      - "8090"
    environment:
      COUCHDB_URL: https://couchdb.${DOMAIN:-agent.falle.se}
      COUCHDB_DB: obsidian
      COUCHDB_USER: ${COUCHDB_USER:-admin}
      COUCHDB_PASSWORD: ${COUCHDB_PASSWORD}
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

volumes:
  postgres_data:

networks:
  default:
    driver: bridge