# ==========================================
# AI Agent Platform - LiteLLM Configuration
# Single unified profile for Llama 3.1 8B
# ==========================================

model_list:
  - model_name: local/llama3-en
    litellm_params:
      model: ollama/llama3.1:8b
  - model_name: rag/llama3-en
    display_name: "RAG -> Llama 3.1 8B"
    litellm_params:
      model: rag/llama3-en
      api_base: http://ragproxy:4080
      temperature: 0.35
      max_output_tokens: 1024
      stream: true

# ---- Routing policy ----
# (No default routing policy defined; alias models are explicit)

# ---- General settings ----
general_settings:
  max_input_tokens: 16000
  max_output_tokens: 2048

# ---- LiteLLM settings ----
litellm_settings:
  budget_limit: 1.50     # USD per dag, 0 = avstangd
  rate_limits:
    - model: local/llama3-en
      rpm: 120

# ---- Logging ----
logging:
  level: INFO
