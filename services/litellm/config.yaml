general_settings:
  max_input_tokens: 128000
  max_output_tokens: 8192

litellm_settings:
  budget_limit: 5.00

logging:
  level: INFO

model_list:
  - model_name: planner
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.1
      max_tokens: 8192
      rpm: 60
      extra_body:
        provider:
          zdr: true

  - model_name: supervisor
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.1
      max_tokens: 16384
      rpm: 20
      extra_body:
        provider:
          zdr: true

  - model_name: software_engineer
    litellm_params:
      model: openrouter/deepseek/deepseek-v3.2
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.0
      max_tokens: 8192
      rpm: 100
      extra_body:
        provider:
          zdr: true

  - model_name: agentchat
    litellm_params:
      model: openrouter/meta-llama/llama-3.3-70b-instruct
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.2
      max_tokens: 8192
      rpm: 60
      extra_body:
        provider:
          zdr: true
        # Llama 3.3 benefits from repetition penalty to reduce tool-call loops
        repetition_penalty: 1.05